<!DOCTYPE html>
<html data-wf-page="5f71dd169010d6326b65485d">

<head>
  <meta charset="utf-8" />
  <title>Seymour • Case Study</title>
  <meta content="width=device-width, initial-scale=1" name="viewport" />
  <link href="assets/css/style.css" rel="stylesheet" type="text/css" />
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:regular,500,600,700" media="all" />
  <script type="text/javascript">
    WebFont.load({ google: { families: ["Inter:regular,500,600,700"] } });
  </script>
  <script type="text/javascript">
    !(function (o, c) {
      var n = c.documentElement,
        t = " w-mod-";
      (n.className += t + "js"),
        ("ontouchstart" in o ||
          (o.DocumentTouch && c instanceof DocumentTouch)) &&
        (n.className += t + "touch");
    })(window, document);
  </script>
  <link href="assets/images/seymour_logo.png" rel="shortcut icon" type="image/x-icon" />
  <link href="assets/images/seymour_logo.png" rel="apple-touch-icon" />
  <script src="https://kit.fontawesome.com/d019875f94.js" crossorigin="anonymous"></script>
  <meta name="image" property="og:image" content="assets/images/thumbnail.png" />
</head>

<body>
  <div class="navigation-wrap">
    <div data-collapse="medium" data-animation="default" data-duration="400" role="banner" class="navigation w-nav">
      <div class="navigation-container">
        <div class="navigation-left">
          <a href="index.html" aria-current="page" class="brand w-nav-brand w—current" aria-label="home">
            <img src="assets/images/seymour.png" alt="" class="template-logo" />
          </a>
          <nav role="navigation" class="nav-menu w-nav-menu">
            <a href="case-study.html" class="link-block w-inline-block">
              <div>Case Study</div>
            </a>
            <a href="team.html" class="link-block w-inline-block">
              <div>The Team</div>
            </a>
          </nav>
        </div>
        <div class="navigation-right">
          <div class="login-buttons">
            <a href="https://github.com/seymour-active-monitoring" target="_blank">
              <span style="color: #161d6f">
                <i class="fab fa-github fa-lg"></i>
              </span>
            </a>
          </div>
        </div>
      </div>
      <div class="w-nav-overlay" data-wf-ignore="" id="w-nav-overlay-0"></div>
    </div>
  </div>
  <div id="sidebar" class="toc">
  </div>
  <div class="section header">
    <article class="container case-study-container">
      <div class="hero-text-container">
        <h1 class="h1 centered">Case Study</h1>
      </div>
      <div id="case-study">

        <br />
        <br />
				<!-- 
				<br />
				<figure>
					<img src="assets/images/case-study/api-calls.png" class="case-study-image" />
					<figcaption>Fig. 13: Dendro's CLI commands abstract away the dozens of API calls to AWS required for setting
						up a pipeline</figcaption>
				</figure>
				<br /> -->
        <!-- Section 1 -->
        <h2 class="h2">1. Introduction</h2>
        <br>
        <h3>1.1. What is Seymour?</h3>
        <p>
					Seymour is an open-source and easy-to-configure active monitoring solution that allows users to simulate requests from globally distributed locations to test their API endpoints. Seymour measures the performance, response time, and correctness of the payload data. We built Seymour to help engineering teams bolster existing testing approaches and handle the challenges of monitoring their increasingly complex systems. Our solution enables rapid detection of issues in production before users experience them. Seymour's infrastructure is easily deployed with a single CLI command and a quick setup.
        </p>
        <br />

        <h3>1.2. What problem does Seymour Solve</h3>
        <p>
					Before we dive further into Seymour and active monitoring, let us take a step back and talk in general about how development teams minimize the risk of bugs reaching production.
				</p>
        <br />
        <p>
					Many of the techniques for accomplishing this fall under the category of testing, which is the process of confirming that software does what it is supposed to do. Good testing helps prevent bugs and can sometimes even help improve performance. Although there is no universally agreed-upon classification, software tests are generally categorized based on purpose and scope. Examples include:  
				</p>
        <br />
				<ul>
					<li>Unit tests: This type of test focuses on a small part of a software system. The "unit" may be one or many classes or functions. These tests are often run by an individual developer even after making small changes to a codebase </li>
				  <li>Integration tests: This type of test is concerned with the entire application with all its parts connected together. These tests can find bugs in the interaction between components in a way that unit tests are not designed to. Remote systems, however, are often mocked.</li>
				  <li>Threshold tests: This type of test compares the actual value of a metric, for example, the performance of a given operation, against a threshold. If the actual value of the metric exceeds the threshold, then the test fails. An inefficient query, for instance, could lead to an operation taking longer than specified by the developer-defined threshold and lead to a test failure.</li>
				</ul>
				<br />
        <p>
					In spite of developers' best efforts, issues still do arise in production. How can this happen, you might wonder? Well: conditions change. Integration tests are often performed only on deployment, meaning tests are run only at the moment in time. Next, only "nearly" perfect replication of the production system occurs in pre-production tests. This is especially true of modern, distributed systems.  Finally, third-party service dependencies can prove to be unreliable.
        </p>
        <br />
				<p>
					On Martin Fowler’s website a contributor wrote this pertinent quote:
				</p>
				<blockquote>
					<i>"In the age of small independent services and frequent deployments, it's very difficult to test pre-production with the exact same combination of versions as they will later exist in production." </i>
				</blockquote>
				martinfolwer.com
        <p>
					So, what happens when issues do arise in production? The end-user’s experience may be degraded or even completely broken. For example, response time can be higher than expected, the response data can be incorrect and, maybe worst of all, an API can be unavailable altogether. Rather than waiting for customers to experience and surface such issues, it would be convenient to test API endpoints in production, continuously. This is exactly where Active monitoring comes into play.
				</p>

        <!-- Section 2 -->
        <h2 class="h2">2. Active Monitoring</h2>
        <h3>2.1 What is Active Monitoring</h3>
        <p>
					Active monitoring, also known as synthetic monitoring, is a technique that runs automated tests against a live production system on a regular basis in order to detect failing business requirements. It helps to continuously monitor server and application performance, even during periods of low user engagement. Tests are written with API consumer expectations in mind to ensure the API provider continues to meet its commitments. 
					There are three broad categories of active monitoring tests: Availability or “uptime”, performance, which is a measure of latency, and Correctness of data. Below is an example test, which is comprised of two assertions:		
        </p>
        <br />
        <figure>
          <img src="assets/images/case-study/dendro-agent.gif" class="case-study-image" />
          <figcaption>Fig. 9: Dendro's CLI helps you install and configure a collection agent on your nodes</figcaption>
        </figure>
        <br />
        <p>
					Here, a GET request to our example endpoint should return a response within 500 milliseconds. The actual response was completed in 632 milliseconds so the assertion would be considered a failure. The second assertion expects the request to return a response status of 200. In this case, the actual status was 200, meaning the assertion is considered passing. But, because our first assertion failed the overall test is still considered failing.
        </p>
        <br />
        <p>
					In the event a given test fails, on-call engineers can be notified through various channels such as Slack or email to begin troubleshooting the underlying problem.
				</p>
        <br />

        <h3>2.2 Why is active monitoring important?</h3>
        <p>
					Things are bound to go wrong in a software production environment. Rather than view this as a bad thing, however, engineering teams can see it as an opportunity to use active monitoring to identify problems in production before users do.
				</p>
        <br />
        <figure>
          <img src="assets/images/case-study/dendro-architecture.gif" class="case-study-image" />
          <figcaption>Fig. 10: An overview of Dendro's architecture, split into conceptual components</figcaption>
        </figure>
        <br />
        <p>
					Active monitoring is especially important in the context of a microservices architecture. Take for example an API endpoint that is dependent on many different services, both internal and external, each of which may be deployed multiple times per day. Including replication of all these services in local CI tests would be slow or brittle at best. Including some services may not be feasible at all.  </p>
        <br />
        <p>
					So, even with a well-maintained test environment, functional and data errors can still slip through the cracks and make their way into production. For the users of a company exposing public APIs, the source of truth is what their experience is when they hit one of these endpoints.
				</p>
        <br />
        <p>
					Furthermore, the best active monitoring solutions provide the ability to originate tests from locations all around the world. This provides insights into how your system is performing for users in specific geographic locations and helps to better diagnose if an issue is network-related. 
        </p>
        <br />
        <p>
					By introducing active monitoring to a holistic testing strategy, engineering tams can sleep better at night knowing that bugs in production will surface fast and be fixed before users are impacted.
        </p>
        <br />

        <!-- Section 3 -->
        <h2 class="h2">3. Solutions</h2>
				<h3>3.1 Existing Solutions</h3>
        <p>
					There are quite a few products offering active monitoring solutions. Some prominent vendors that offer this service are New Relic and Datadog, followed by some smaller-scale companies like Uptrends, Checky and Runscope. There are also a handful of open-source solutions. One is called Monika and another is offered by Artillery, which is more commonly known for load testing. Besides using a SaaS or open-source active monitoring product, some teams may decide on a DIY approach and build their own in-house solution. Let’s weigh the pros and cons of each of these options by considering their various capabilities and feature sets.
        </p>
				<br />
				<figure>
					<img src="assets/images/case-study/comparison-table.png" class="case-study-image" />
					<figcaption>Fig. 13: Comparing Seymour to other solutions on the market
						up a pipeline</figcaption>
				</figure>
				<br /> 
        <p>
					In general, SaaS active monitoring products offer geographic distribution of request locations. Typically, these solutions are managed, meaning there’s very little to zero setup required from the customer to configure their first test. Additionally, most of the interactions with these SaaS products, including New Relic and Checkly, are through a UI, which makes setting up new tests easy for all users, including non-engineers. One drawback of a managed solution, however, is the lack of data ownership. This might be a deal breaker for some companies who don’t want their test data residing on a third-party provider’s infrastructure. SaaS solutions typically offer a wide variety of features, including native alerting over a variety of channels. Some additional features include teardown scripts and integration into CI/CD pipelines. All of this functionality, some of which might not be needed for a given use case, does come at a direct financial cost. SaaS solutions are the most expensive option.
        </p>
				<br />
        <br />
        <p>
					On the other hand, choosing an open-source solution allows the users to maintain complete control over their data, and these solutions are usually free. However, these solutions don’t typically offer geographic distribution of tests, at least in their free tiers. Additionally, these solutions are more laborious to set up and use as compared to SaaS solutions. Both Monika and Artillery, for instance, are set up via a multi-step process and tests are configured via YAML. There is no UI.
				</p>
        <br />
        <p>
					On the other side of the spectrum, we have in-house solutions. This could either entail building a system from the ground up or wrapping an existing open source solution like Monika. A major appeal of this approach is that by definition the user can customize the solution to fit their specific needs, which can of course include maintaining complete control over their data. A significant drawback of this approach, however, is the amount of time and effort required to develop such a solution and would require engineering resources that could be otherwise spent on more mission-critical tasks.
        </p>
        <br />
				<h3>3.2 Introducing Seymour</h3>
        <br />
        <p>
					Having surveyed available active monitoring solutions, what we found was lacking was an open-source, self-hosted, easy-to-configure monitoring solution that allows running tests from globally distributed locations.   </p>
        <br />
        <p>
					That’s why we built Seymour.   geographic distribution, allowing users to configure tests originating in 22 global locations. Seymour is easy to use. Although not as simple to set up as a managed SaaS product, as we’ll discuss later, provisioning Seymour requires only two CLI commands. Once it is set up, all test and alert configurations are done through a UI, although Seymour also exposes an API enabling programmatic configuration if that’s what the user prefers. Because Seymour is open-source and self-hosted, it allows users to maintain sole ownership of their data. Seymour enables users to configure alerts to be sent over one or more of three channels including e-mail, Slack, and Discord. And finally, since the only cost of Seymour is the cost of the AWS infrastructure it runs on, it’s inexpensive, especially relative to its SaaS counterparts.
        </p>
        <br />
				<h3>3.3 UI/ UX Demo</h3>
				<iframe width="560" height="315" src="https://www.youtube.com/embed/167arvL_SbY" title="YouTube video player" frameborder="0" allow="accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
				<h3>3.4 Deployment</h3>
        <p>
					Getting started with Seymour is straightforward. An AWS account is required, but once that’s set up all that’s left is to:
        </p>
        <br />
				<ol>
					<li>
						Clone the Seymour infra-setup repo which can be found at https://github.com/No-Name-temporary/infra-setup
					</li>
					<li>
						Run two CLI commands and wait while approximately 50 (note: don’t emphasize) AWS resources are spun up in your account
					</li>
					<li>
						Enter the generated URL in your browser
					</li>
				</ol>
				</br>
				<p>
					With that done, you’re ready to configure your first test! One thing worth noting, however, is that the provisioning of AWS resources, while automated, may take upwards of 20 minutes, primarily due to the provisioning of resources in 22 remote regions.
				</p>
        <!-- Section 4 -->
        <h2 class="h2">4. Seymour's architecture</h2>
				<h3>4.1. Overview</h3>

        <p>
					Seymour’s infrastructure can be thought of as loosely organized into four main sections which together make up the lifecycle loop of a single test. First, we have the Test Configuration phase where tests are defined and saved. Then there is a Pre-Processing phase which preps each test run with a test configuration and proper routing to the geographic regions where it’s needed to run. Next, is the Test Execution phase, where the actual HTTP request is made to the endpoint and the response is checked against the assertions in the test configuration. The results are packaged up and sent to the final phase, Post Processing. This is where test results are stored and alerting is triggered in the event of a failed test.
        </p>
        <br />
				<p>
					Before moving on let’s define Home and Remote regions. When a user deploys Seymour, the user must select a main AWS region in which to set up the infrastructure. That’s what we are referring to here as the Home Region. Everything needed to power the UI, the Backend Server, as well as the Test Configuration, Pre-Processing, and Post-Processing phases reside in the Home Region. The test execution happens in any number of the AWS regions selected when configuring a test, so the infrastructure for that phase is set up in all other available AWS regions, which we refer to here as Remote Regions. 
				</p>
				<br />
				<p>
					Next, let’s take a turn in each phase to walk through the details of a single test’s journey through the loop.
				</p>
				<br />
        <h3>4.2. Test Configuration</h3>
        <p>
					The journey of a test through the infrastructure begins as a JSON configuration file sent from the UI when a user first schedules a test. The backend app first stores the test configuration in the database. Afterward, it adds the test ID to the JSON config and uses the AWS SDK to create a new rule in the EventBridge service. 
        </p>
        <br />
        <p>
					EventBridge is a serverless event bus and is typically a cornerstone in AWS-based event-driven architectures. While EventBridge is a multi-faceted service, we are essentially using its scheduling capabilities as a CRON job. An EventBridge rule, for our purposes, is a scheduled event action that fires on a fixed recurring interval with a specific target. The interval is specified when scheduling the test, and the rule is created to fire on that same interval. The JSON test configuration is saved to the rule as the fixed payload for the event action every time it fires off to the target. The CRUD app isn't needed at all during the ongoing life of a test once it has been scheduled.
        </p>
        <br />
        <h3>4.3. Pre-processing</h3>
        <p>
					The Pre-Processing phase is where each scheduled test run fires, and our JSON test config kicks off through the loop. We walked through what EventBridge is doing before, so we know that the rule fires on a schedule, but I left off the target for where the rule fires to. 
					The target destination is a Lambda function we refer to as Route Packager, which is the same target for every scheduled rule.					
        </p>
        <br />
				<p>
					Route Packager's purpose is to read all the location data from the JSON test configuration payload and prep it for routing to the correct regions. It then publishes a message with the test to a topic in SNS, Amazon's Simple Notification Service. A queue in each region is subscribed to the topic and will only accept messages if they are intended for that region. 
				</p>
				<br />

        <h3>4.4. Test execution</h3>
        <p>
					Up to this point all the infrastructure we have looked at has been within the home region, this, the Test Execution phase, is a look at what is going on in each remote region. As mentioned previously, there is a queue that first receives the message in each remote region. The message is pulled from the queue by a Lambda function we refer to as Test Runner. Now the JSON test config has made its journey to the point where it’s actually needed for making the HTTP request. Test Runner uses the config data to make a request on the endpoint and then compare the response to the expected response values in the assertions. If any of the assertions fail, then the whole test is marked as failed. It then packages up the results and sends them back to the Home Region. </p>
        <br />
				<h3>4.5. Post-processing</h3>
        <p>
					In the home region, the test results are received in a queue. They are processed from the queue by a Lambda function we refer to as the Test Result Handler. The result handler first examines the results for whether the test succeeded or failed. If it finds that the test failed, it immediately invokes another Lambda, which handles alerting. Regardless of whether the test succeeded or failed, Result Handler then proceeds to write the results to the database. Before wrapping up here, let's circle back to the Lambda, which handles alerts. When invoked, it receives in its payload information about the test which failed. It then queries the database to get that test's alerting information and sends an alert message to each configured destination.
        </p>
        <br />

        <!-- Section 5 -->
        <h2 class="h2">5. Engineering decisions and challenges</h2>
				<h3>5.1. Build from bottom-up or wrap open-source?</h3>
				<h4>Monika</h4>
        <p>
					During our project research phase, after the team settled on our problem domain we were quickly faced with a critical decision: should we wrap an open source project to achieve our goals or should we build something from the bottom up? Let’s first take a closer look at Monika, one of the open-source projects discussed in the overview of existing solutions.
				</p>
        <br />
				<p>
					Monika bills itself as a synthetic monitoring application. Just like Seymour, Monika is designed to send out HTTP requests and assess the responses. This project was especially compelling to the team because it provided a lot of the functionality that we wanted to provide to Seymour users. Out of the box, Monika can: 
				</p>
				<ul>
					<li>run complex API tests on scheduled intervals</li>
					<li>handle alerting through integrations with a number of popular platforms</li>
					<li>and being open-source, users are able to maintain ownership of their data</li>   
				</ul>
				<br />
				<p>
					We used Monika quite a bit in our research and while it works well, it was still lacking critical features that were important to the team. 
				</p>
				<br />
				<p>
					First and foremost, Monika lacked the ability to originate tests from a variety of geographic locations. It’s limited to sending HTTP requests from the server instance the app is running on.
				</p>
				<br />
				<p>
					We also homed in on the difficulty of using Monika which is a command-line tool and does not come with a user interface. As Scott alluded to earlier, the team’s goal was for Seymour to be easy enough to use by engineers and non-engineers alike. With Monika, test settings and configurations are defined through yaml files which first require a read through Monika’s docs to learn its specific syntax. Test result data is available in the form of raw logs and an SQLite database. It’s also able to integrate with Prometheus, an observability data aggregation tool. However, by default, Monika only exposes four metrics including total tests, status code info, response time, and a tally of triggered alerts. On the whole, we found the level of user effort required to be more intensive than what we had in mind, especially for a non-technical user. 
				</p>
				<br />
				<p>
					With a solid understanding of what Monika could and could not do, we then took a hard look at wrapping and extending Monika to achieve all of our requirements. If Monika already provided half of Seymour, we could focus more time on features and polish, or so we thought.
				</p>
				<br />
				<h4>Wrap?</h4>
				<p>
					After the assessment, we felt we could add a user interface and expanded metrics with relative ease. A much bigger challenge came into focus, however, when we looked at multi-region testing. 
				</p>
				<br />
				<p>
					Because Monika requires a constantly running process, in order to give our users the option to generate multi-region tests, we would’ve had to deploy the app to dedicated virtual machines in each of the 22 AWS regions we planned to support. This approach presented a number of thorny questions:
				</p>
				<ol>
					<li>
						First, each virtual machine would require security, networking, and application configuration upon deployment. How would we make that easy for the user?
					</li>
					<li>
						To generate tests, a Monika instance must read from a local yaml configuration file. How would we make sure that the config files were all in sync across the virtual machines?
					</li>
					<li>
						Lastly, 22 virtual machines would be inherently difficult to maintain. How would we ensure the reliability of what was supposed to be an easy-to-use monitoring tool?
					</li>
				</ol>
				<br />
				<p>
					After considering potential solutions to these problems, we came to the conclusion that deploying Monika to multiple regions would require sub-optimal infrastructure decisions. We believed we could develop our own solution that avoided these challenges and resulted in an improved final architecture.
				</p>
				<br />
				<h4>Build</h4>
				<p>
					As Miles demonstrated in his overview of Seymour’s architecture, we ended up utilizing lambda functions to achieve our requirement of multi-region testing. Instead of deploying an entire virtual machine running Monika to remote regions, Seymour simply deploys the test-runner lambda function, coupled with a queue. Although we had to write more custom code, we found this setup to be superior in the following ways:
				</p>
				<br />
				<ol>
					<li>
						First, the test-runner lambda function is easily deployed to all AWS regions with AWS’s Cloud Development Kit or CDK.  This eliminates the need to configure any virtual machines.
					</li>
					<li>
						The test-runner lambda function is stateless. All of the scheduling and configuration logic remains in the home region and is communicated to the test-runner via SNS, the message broadcasting tool Miles mentioned in the architecture overview
					</li>
					<li>
						And by placing a queue in front of the test-runner lambda, we get a high degree of assurance that the test-runner will process incoming SNS messages
					</li>
					<li>
						Communication of test runner's results back to the home region is simple thanks to lambda’s ability to send invocation records to a queue destination in another region
					</li>
					<li>
						Rather than a constantly running virtual machine, the test-runner is invoked on demand. This reduces maintenance needs, and also reduces costs
					</li>
					<li>
						Lambda functions scale on-demand, out of the box. If a user configures dozens of tests to run in the same region at the exact same time, the test-runner can handle the load.
					</li>
				</ol>
				<br />
				<p>
				  In the end, by building Seymour from the ground up, we were able to fully take advantage of AWS cloud-native products, resulting in easy deployment and a low-maintenance user experience.
			  </p>

        <h3>5.2. Why are we using Route Packager</h3>
        <p>
					Our journey to building the route-packager lambda function also comprised an interesting set of design decisions. If you recall from the walk-through of Seymour’s architecture, the route-packager is the target for all scheduler “rules”. Also recall that “rules”, in the context of Seymour, are simply scheduled events with an attached JSON test configuration.
        </p>
        <br />
        <p>
					We knew from the outset that we wanted to enable broad-based global testing capability with an efficient use of resources. Deploying the test-runner to all remote regions achieved part of this plan, but how to communicate scheduled test configurations to the test-runner was not immediately apparent. 
        </p>
        <br />
        <p>
					One option we looked at was directly invoking remote region test-runner lambdas from the scheduler rules. While EventBridge is technically capable of this, there is a 5 target limit for any given rule. Because we wanted to support 22 targets, one for each region, we quickly discarded this approach. 
				</p>
        <br />
        <p>
					We also tried using EventBridge’s “event bus” functionality, which is essentially another interface for communicating events in AWS, to connect home and remote regions. This approach denied us the ability to easily pass through test configuration JSON data, however, and was also discarded. 
        </p>
        <br />
				<p>
					Ultimately, we landed on using SNS as the medium through which scheduler events were distributed because of its ability to widely broadcast a message containing the test configuration across regions.
				</p>
        <br />
        <p>
					In order to make this message distribution more targeted, we added message filtering logic to the SNS topic subscriptions for each region so that only messages intended for a given region were added to the queue for processing by the test-runner. 		
				</p>
        <br />
        <p>
					We still needed one last piece of functionality to make this work, however. In order for the subscription filters to work, we needed to add some region metadata to the message, functionality that EventBridge does not provide. </p>
        <br />
				<p>
					This is why we decided to build the route-packager lambda function. In Seymour’s final architecture, each fired rule first travels to the route-packager which translates the location data from the test configuration into attributes that it adds to the message before publishing to the SNS topic.
				</p>
        <p>
					So, by combining route-packager and SNS in the pre-processing phase of Seymour’s test loop,  we were able to achieve our goal of efficient distribution of tests to the remote regions.
				</p>
        <br />

        <h3>5.3. The outcome: system resiliency</h3>
        <p>
					Resiliency was at the top of mind at each phase of building Seymour because after all, what good would an active monitoring tool be if it was brittle or prone to crashing? 
        </p>
        <br />
				<p>
					There are three pillars in Seymour’s overall approach to system resiliency:
				</p>
        <br />
        <p>
					First, we reached for AWS’s serverless offerings, including lambda functions, throughout the test loop. As discussed in the wrap vs. build section, using serverless allows Seymour to shift a good portion of operational responsibility and infrastructure management to AWS. 
				</p>
        <br />
        <p>
					Furthermore, by using AWS’s managed messaging services, we were able to decouple individual components within the test loop as well as the test loop from the rest of the system. This design provides assurances that test runs will be processed eventually even in cases of extremely high volume or if one of the loop components fails. As Miles mentioned earlier, once a test is configured, it is able to run and generate alerts even if the UI, backend app, and database go down.  </p>
        <br />
        <p>
					Lastly, we chose to deploy the backend app using AWS’s Elastic Beanstalk service, which reduces the risk of failures through automatic capacity provisioning, load balancing and auto-scaling. Because the underlying infrastructure is fully managed by AWS, Elastic Beanstalk also provides automatic failover for terminated or unavailable instances.  </p>
        <br />
        <h3>5.4. CDK: Cross-Region Automated Deployment</h3>
        <p>
					One of the foremost challenges we faced in building Seymour was automating the deployment of AWS resources across multiple regions. Because ease-of-deployment was one of our main goals for the project, we wanted to limit as much as possible the amount of infrastructure configuration required of the user.
        </p>
        <br />
        <p>
					To automate the process of configuring and deploying AWS resources, we used two main tools: The Cloud Development Kit, or CDK and the Software Development Kit, or SDK.
				</p>
        <br />
        <p>
					CDK is an AWS service used to programmatically set up, modify and tear down resources. The CDK was relatively straightforward to work with for deploying and connecting infrastructure within the home region. However, this same approach did not work when it came to connecting resources between the home and remote regions.
        </p>
        <br />
				<p>
					One way of implementing a multi-region deployment is using a CDK pipeline. However, we continued to look for a different way because of the additional burden of complexity caused by adding the pipeline. There would be a one-time technical burden on us to implement the pipeline, but it also added several more pieces of complexity for the eventual user just to get Seymour deployed on their own account. Technically this would work and it remained a fallback option for us.
				</p>
        <br />
        <p>
					Ultimately we were able to avoid having to use the CDK pipeline. We did this by using a different AWS tool, the SDK. While the CDK is specifically purposed for setting up, modifying, or tearing down resources, the SDK enables cross-region communication at runtime. We added some code to the Test Runner lambda function so that when invoked it can use the SDK to connect to the Home Region. This kept the deployment process lean and the complexity to a minimum for the installing user. </p>
        <br />

        <!-- Section 6 -->
        <h2 class="h2">6. Future work</h2>
				<p>
					We believe Seymour provides a great active monitoring solution, but we're also excited about expanding its functionality. Here are some of the features we'd like to implement in future iterations:
				</p>
        <ul>
          <li>
						<h6>'Smart' alerting</h6>
						At the moment, Seymour provides three ways of alerting: Slack and Discord via webhooks or email via SES (Amazon's Simple Email Service). One of the limitations is that the alerting system triggers notifications for every failed test. This means that a test failure in twelve different locations consequently triggers twelve separate alerts, and there is no test retry functionality. In the future, we would like to implement a feature allowing users to determine how many fails they wish to be notified on, along with alerts aggregation.
          </li>
          <li>
						<h6>Teardown scripts</h6>
						Currently, Seymour does not have the functionality to add custom scripts, but it's something we have considered for our future work. Tear-down scripts execute after the HTTP request is made and have access to response objects. They could be used, for example, to send additional requests to clear the test data in the database after sending a POST request test.
					</li>
          <li>
						<h6>Allowing integration with a CI/CD pipeline</h6>
						Lastly, Seymour allows to either configure tests to run on a schedule as frequent as every one minute or to invoke the test on demand with 'run now' functionality. It doesn't, however, have the functionality to be invoked automatically by a third-party actor and so lacks integration ability with a CI/CD pipeline.
          </li>
        </ul>


        <!-- Section 7 -->
        <h2 class="h2">7. Glossary</h2>

        <!-- Section 8 -->
        <h2 class="h2">8. References</h2>


        <!-- Section 9 -->
        <h2>9. Team</h2>
        <br>
        <br>
        <div class="section team-section">
          <div class="container">
            <div data-duration-in="300" data-duration-out="100" class="tabs w-tabs">
              <div data-w-id="8ce4324a-ed8e-4436-9964-0cfbaf67c64a" style="
                    transform: translate3d(0px, 55px, 0px) scale3d(1, 1, 1)
                      rotateX(0deg) rotateY(0deg) rotateZ(0deg) skew(0deg, 0deg);
                    transform-style: preserve-3d;
                    opacity: 0;
                  " class="tabs-content w-tab-content">
                <div>
                  <div class="team-grid">
                    <div class="team-member-wrap">
                      <img src="assets/images/team/scott_circle.png" loading="lazy" alt="" />
                      <div class="team-member-info">
                        <div class="team-member-name">Scott Graham</div>
                        <div class="team-member-location">San Francisco, CA</div>
                      </div>
                      <ul class="team-member-icons">
                        <li>
                          <a href="mailto:scttgrhm7@gmail.com" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-envelope"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://scttgrhm.dev/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-globe"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://www.linkedin.com/in/scott-graham-96a57944/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-linkedin"></i>
                            </span>
                          </a>
                        </li>
												<li>
                          <a href="https://github.com/scogra17" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-github"></i>
                            </span>
                          </a>
                        </li>
                      </ul>
                    </div>
                    <div class="team-member-wrap">
                      <img src="assets/images/team/tim_circle.png" loading="lazy" alt="">
                      <div class="team-member-info">
                        <div class="team-member-name">Tim Dronkers</div>
                        <div class="team-member-location">Denver, CO</div>
                      </div>
                      <ul class="team-member-icons">
                        <li>
                          <a href="mailto:tim@dronkers.dev" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-envelope"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://www.dronkers.dev/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-globe"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://www.linkedin.com/in/timdronkers/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-linkedin"></i>
                            </span>
                          </a>
                        </li>
												<li>
                          <a href="https://github.com/mabbason" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-github"></i>
                            </span>
                          </a>
                        </li>
                      </ul>
                    </div>
                    <div class="team-member-wrap">
                      <img src="assets/images/team/miles_circle.png" loading="lazy" alt="">
                      <div class="team-member-info">
                        <div class="team-member-name">Miles Abbason</div>
                        <div class="team-member-location">Durham, NC</div>
                      </div>
                      <ul class="team-member-icons">
                        <li>
                          <a href="mailto:miles.abbason@gmail.com" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-envelope"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="case-study.html" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-globe"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://www.linkedin.com/in/miles-abbason-a593b929/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-linkedin"></i>
                            </span>
                          </a>
                        </li>
												<li>
                          <a href="https://github.com/mabbason" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-github"></i>
                            </span>
                          </a>
                        </li>
                      </ul>
                    </div>
                    <div class="team-member-wrap">
                      <img src="assets/images/team/kat_circle.png" loading="lazy" alt="">
                      <div class="team-member-info">
                        <div class="team-member-name">Katarina Rosiak</div>
                        <div class="team-member-location">Stockholm, Sweden</div>
                      </div>
                      <ul class="team-member-icons">
                        <li>
                          <a href="mailto:katarinarosiak@gmail.com" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-envelope"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://katarinarosiak.com/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fas fa-globe"></i>
                            </span>
                          </a>
                        </li>
                        <li>
                          <a href="https://www.linkedin.com/in/katarzyna-katarina-rosiak-467465b7/" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-linkedin"></i>
                            </span>
                          </a>
                        </li>
												<li>
                          <a href="https://github.com/katarinarosiak" target="_blank">
                            <span class="team-member-icon">
                              <i class="fab fa-github"></i>
                            </span>
                          </a>
                        </li>
                      </ul>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
    </article>
    <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=5f71dd169010d641cf65485c"
      type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
      crossorigin="anonymous"></script>
    <script src="https://assets.website-files.com/5f71dd169010d641cf65485c/js/webflow.6af2032ff.js"
      type="text/javascript"></script>
    <script>
      /*!
       * toc - jQuery Table of Contents Plugin
       * v0.3.2
       * http://projects.jga.me/toc/
       * copyright Greg Allen 2014
       * MIT License
      */
      !function (a) { a.fn.smoothScroller = function (b) { b = a.extend({}, a.fn.smoothScroller.defaults, b); var c = a(this); return a(b.scrollEl).animate({ scrollTop: c.offset().top - a(b.scrollEl).offset().top - b.offset }, b.speed, b.ease, function () { var a = c.attr("id"); a.length && (history.pushState ? history.pushState(null, null, "#" + a) : document.location.hash = a), c.trigger("smoothScrollerComplete") }), this }, a.fn.smoothScroller.defaults = { speed: 400, ease: "swing", scrollEl: "body,html", offset: 0 }, a("body").on("click", "[data-smoothscroller]", function (b) { b.preventDefault(); var c = a(this).attr("href"); 0 === c.indexOf("#") && a(c).smoothScroller() }) }(jQuery), function (a) { var b = {}; a.fn.toc = function (b) { var c, d = this, e = a.extend({}, jQuery.fn.toc.defaults, b), f = a(e.container), g = a(e.selectors, f), h = [], i = e.activeClass, j = function (b, c) { if (e.smoothScrolling && "function" == typeof e.smoothScrolling) { b.preventDefault(); var f = a(b.target).attr("href"); e.smoothScrolling(f, e, c) } a("li", d).removeClass(i), a(b.target).parent().addClass(i) }, k = function () { c && clearTimeout(c), c = setTimeout(function () { for (var b, c = a(window).scrollTop(), f = Number.MAX_VALUE, g = 0, j = 0, k = h.length; k > j; j++) { var l = Math.abs(h[j] - c); f > l && (g = j, f = l) } a("li", d).removeClass(i), b = a("li:eq(" + g + ")", d).addClass(i), e.onHighlight(b) }, 50) }; return e.highlightOnScroll && (a(window).bind("scroll", k), k()), this.each(function () { var b = a(this), c = a(e.listType); g.each(function (d, f) { var g = a(f); h.push(g.offset().top - e.highlightOffset); var i = e.anchorName(d, f, e.prefix); if (f.id !== i) { a("<span/>").attr("id", i).insertBefore(g) } var l = a("<a/>").text(e.headerText(d, f, g)).attr("href", "#" + i).bind("click", function (c) { a(window).unbind("scroll", k), j(c, function () { a(window).bind("scroll", k) }), b.trigger("selected", a(this).attr("href")) }), m = a("<li/>").addClass(e.itemClass(d, f, g, e.prefix)).append(l); c.append(m) }), b.html(c) }) }, jQuery.fn.toc.defaults = { container: "body", listType: "<ul/>", selectors: "h1,h2,h3", smoothScrolling: function (b, c, d) { a(b).smoothScroller({ offset: c.scrollToOffset }).on("smoothScrollerComplete", function () { d() }) }, scrollToOffset: 0, prefix: "toc", activeClass: "toc-active", onHighlight: function () { }, highlightOnScroll: !0, highlightOffset: 100, anchorName: function (c, d, e) { if (d.id.length) return d.id; var f = a(d).text().replace(/[^a-z0-9]/gi, " ").replace(/\s+/g, "-").toLowerCase(); if (b[f]) { for (var g = 2; b[f + g];)g++; f = f + "-" + g } return b[f] = !0, e + "-" + f }, headerText: function (a, b, c) { return c.text() }, itemClass: function (a, b, c, d) { return d + "-" + c[0].tagName.toLowerCase() } } }(jQuery);
    </script>
    <script>
      /* initialize */
      $('.toc').toc({
        'selectors': 'h2', //elements to use as headings
        'container': 'article', //element to find all selectors in
        'smoothScrolling': true, //enable or disable smooth scrolling on click
        'prefix': 'toc', //prefix for anchor tags and class names
        'highlightOnScroll': true, //add class to heading that is currently in focus
        'highlightOffset': 100, //offset to trigger the next headline
      });
    </script>
</body>

</html>


<!-- 
<br />
<figure>
	<img src="assets/images/case-study/api-calls.png" class="case-study-image" />
	<figcaption>Fig. 13: Dendro's CLI commands abstract away the dozens of API calls to AWS required for setting
		up a pipeline</figcaption>
</figure>
<br /> -->